{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean Vs Crack Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz1TtqNWCDeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "034c95c4-7df9-4517-e778-ba2ad224e769"
      },
      "source": [
        "#Dataset is uploaded to gdrive, so will be mounting my drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p7_LiTXCXjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# changing working directory to the dataset directory\n",
        "import os\n",
        "os.chdir('drive/My Drive') "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxhiJZnLCxMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4b30ba89-f6eb-4590-fd68-bb23223267de"
      },
      "source": [
        "# importing the required libraries for data pre-processing and model traning\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dense, Dropout, Input, Flatten\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt  \n",
        "import seaborn as sns\n",
        "\n",
        "from imutils import paths\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import csv\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# random.seed(42) #To get same random values each time\n",
        "\n",
        "#to Load Truncated images\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ffZaFTGnhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Input model dimensions\n",
        "img_width = 128\n",
        "img_height = 128\n",
        "dataset = './dataset'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F5Mce-ADva5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# grab the image paths of all input images to model and randomly shuffle them\n",
        "imagePaths = sorted(list(paths.list_images(dataset))) \n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "    img = image.load_img(imagePath, target_size=(img_width, img_height,3))\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    data.append(img)\n",
        "    \n",
        "    # extract set of class labels from the image path and update the labels list\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    if label == \"healthy\":\n",
        "      label = 1\n",
        "    elif label == \"cracked\":\n",
        "      label = 0\n",
        "    labels.append(label)\n",
        "    \n",
        "#Convert labels and data in numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeNd4-unDvsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# partition the data into training  80% and testing 20% splits\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, random_state=42)\n",
        "\n",
        "# construct the image generator for data augmentation (Data is very less, this will improve the model)\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "\t                      horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukc76onTDvqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfb3c63d-423e-4ace-fbc5-2430424eb105"
      },
      "source": [
        " #Applying Transfer Learning \n",
        "base_model = ResNet50(input_shape=data[0].shape, include_top=False, weights='imagenet')\n",
        "base_model.trainable = True #Allowing model to trainable (as data is too less)\n",
        "base_model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 8, 8, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tq1tdWoDvox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_mod = base_model.output\n",
        "res_mod = AveragePooling2D(pool_size=(4,4))(res_mod)\n",
        "res_mod = Flatten(name=\"flatten\")(res_mod)\n",
        "res_mod = Dense(256, activation=\"relu\")(res_mod)\n",
        "res_mod = Dropout(0.5)(res_mod)\n",
        "res_mod = Dense(1, activation='sigmoid')(res_mod)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5LhoJekDvmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ecf6c82-7d35-4480-9aaa-bdaf86b65958"
      },
      "source": [
        "model = Model(inputs=base_model.input, outputs=res_mod)\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 134, 134, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 64, 64, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 64, 64, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 66, 66, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 32, 32, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 32, 32, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 32, 32, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 32, 32, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 32, 32, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 32, 32, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 32, 32, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 32, 32, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 32, 32, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 32, 32, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 32, 32, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 32, 32, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 32, 32, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 32, 32, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 32, 32, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 32, 32, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 32, 32, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 16, 16, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 16, 16, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 16, 16, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 16, 16, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 16, 16, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 16, 16, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 16, 16, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 16, 16, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 16, 16, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 16, 16, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 16, 16, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 16, 16, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 16, 16, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 16, 16, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 16, 16, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 256)    131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 8, 8, 256)    0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 8, 8, 256)    0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 8, 8, 1024)   525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 8, 8, 1024)   0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 8, 8, 256)    0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 8, 8, 256)    0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 8, 8, 1024)   0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 8, 8, 1024)   0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 8, 8, 256)    0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 8, 8, 256)    0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 8, 8, 1024)   0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 8, 8, 1024)   0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 8, 8, 256)    0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 8, 8, 256)    0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 8, 8, 1024)   0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 8, 8, 1024)   0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 8, 8, 256)    0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 8, 8, 256)    0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 8, 8, 1024)   0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 8, 8, 1024)   0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 256)    262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 8, 8, 256)    0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 8, 8, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 8, 8, 1024)   0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 4, 4, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 4, 4, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 4, 4, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 4, 4, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          524544      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            257         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,112,513\n",
            "Trainable params: 24,059,393\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO4pihg4Ni_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the number of epochs to train for, initia learning rate, and batch size\n",
        "Epochs = 250\n",
        "learning_rate = 1e-4\n",
        "batch_size = 16"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzEjgBuGDvkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "d0270ebd-af8f-4e35-fd2a-70305693d735"
      },
      "source": [
        "opt = Adam(lr= learning_rate, decay= learning_rate / Epochs)\n",
        "model.compile(optimizer=opt, loss= \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# Early Stopping If model is not improving on validation set\n",
        "stop = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.00001, patience=15, restore_best_weights=True)\n",
        "\n",
        "#Training the model for 250 epochs\n",
        "H = model.fit(aug.flow(trainX, trainY, batch_size=batch_size), validation_data=(testX, testY), epochs=Epochs, callbacks=[stop])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "12/12 [==============================] - 3s 282ms/step - loss: 0.8579 - accuracy: 0.5053 - val_loss: 0.7703 - val_accuracy: 0.4792\n",
            "Epoch 2/250\n",
            "12/12 [==============================] - 1s 97ms/step - loss: 0.5392 - accuracy: 0.7211 - val_loss: 0.6962 - val_accuracy: 0.5208\n",
            "Epoch 3/250\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.5213 - accuracy: 0.7474 - val_loss: 1.2695 - val_accuracy: 0.5208\n",
            "Epoch 4/250\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.3617 - accuracy: 0.8579 - val_loss: 2.2743 - val_accuracy: 0.5208\n",
            "Epoch 5/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.3538 - accuracy: 0.8526 - val_loss: 2.0486 - val_accuracy: 0.5208\n",
            "Epoch 6/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.3074 - accuracy: 0.8842 - val_loss: 2.9162 - val_accuracy: 0.5208\n",
            "Epoch 7/250\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.2296 - accuracy: 0.9263 - val_loss: 2.4244 - val_accuracy: 0.5208\n",
            "Epoch 8/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.2017 - accuracy: 0.9263 - val_loss: 3.0722 - val_accuracy: 0.5208\n",
            "Epoch 9/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.2490 - accuracy: 0.8947 - val_loss: 5.2119 - val_accuracy: 0.5208\n",
            "Epoch 10/250\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.2118 - accuracy: 0.9316 - val_loss: 5.5122 - val_accuracy: 0.5208\n",
            "Epoch 11/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.2025 - accuracy: 0.9263 - val_loss: 4.7477 - val_accuracy: 0.5208\n",
            "Epoch 12/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.2056 - accuracy: 0.9368 - val_loss: 7.2640 - val_accuracy: 0.5208\n",
            "Epoch 13/250\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.1071 - accuracy: 0.9632 - val_loss: 7.4113 - val_accuracy: 0.5208\n",
            "Epoch 14/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0812 - accuracy: 0.9684 - val_loss: 7.7615 - val_accuracy: 0.5208\n",
            "Epoch 15/250\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.1070 - accuracy: 0.9526 - val_loss: 6.8260 - val_accuracy: 0.5208\n",
            "Epoch 16/250\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0800 - accuracy: 0.9789 - val_loss: 7.8804 - val_accuracy: 0.5208\n",
            "Epoch 17/250\n",
            "12/12 [==============================] - 1s 93ms/step - loss: 0.1031 - accuracy: 0.9737 - val_loss: 8.3050 - val_accuracy: 0.5208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHEvBq3DvhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "21d28db6-d281-4748-eba9-55a1a62131bd"
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "#Model stopped improvement at 26 steps so training is stopped at that point\n",
        "Epochs = 17\n",
        "\n",
        "plt.plot(np.arange(0, Epochs), H.history[\"loss\"], label= \"train_loss\")\n",
        "plt.plot(np.arange(0, Epochs), H.history[\"val_loss\"], label= \"val_loss\")\n",
        "plt.plot(np.arange(0, Epochs), H.history[\"accuracy\"], label= \"train_acc\")\n",
        "plt.plot(np.arange(0, Epochs), H.history[\"val_accuracy\"], label= \"val_acc\")\n",
        "\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff218d50320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8IbCabUDveq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "296e032e-f44a-4284-ce48-2cffd3a75d55"
      },
      "source": [
        "#Calculating Model's Accuracy on Test Data\n",
        "results = model.evaluate(testX, testY, batch_size=4)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6962 - accuracy: 0.5208\n",
            "test loss, test acc: [0.6962103843688965, 0.5208333134651184]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NUGYt3QCxIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "cea014d4-58cd-428f-e157-5c4696a73f2e"
      },
      "source": [
        "#Will be designing the model in TensorFlow based Keras package\n",
        "Y_pred = model.predict_generator(testX, 48 // 4)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(testY, y_pred)\n",
        "print(cm)\n",
        "print('Classification Report')\n",
        "print(classification_report(testY, y_pred))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[23  0]\n",
            " [25  0]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      1.00      0.65        23\n",
            "           1       0.00      0.00      0.00        25\n",
            "\n",
            "    accuracy                           0.48        48\n",
            "   macro avg       0.24      0.50      0.32        48\n",
            "weighted avg       0.23      0.48      0.31        48\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y6NMdvvCxFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}